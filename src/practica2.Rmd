---
title: 'Práctica 2: Limpieza y análisis de datos'
author: "Miguel Santos Pérez  y Alejandro Arzola García"
date: "17 de junio de 2020"
output:
  pdf_document:
    number_sections: yes
    toc: yes
    toc_depth: '2'
  html_document:
    df_print: paged
    toc: yes
    toc_depth: '2'
subtitle: UOC - Tipología y ciclo de vida de los datos
toc-title: Índice
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r,eval=TRUE,echo=FALSE}
# Definir directorio de trabajo para Miguel
setwd("C:/Users/USER-PC/Desktop/tipologia")
# Definir directorio de trabajo para Alejandro
#setwd('/Users/aarzola/Desktop/UOC/1920.S2 - Tipología y ciclo de vida de los datos/PEC_PRAC/PRAC_2/src')
```

\newpage
****

```{r,eval=TRUE,echo=TRUE}
 # Cargamos las librerías necesarias para el proyecto
suppressMessages(library(dplyr)) 
suppressMessages(library(plyr))
suppressMessages(library(data.table))
suppressMessages(library(ggcorrplot))
suppressMessages(library(pROC))
suppressMessages(library(factoextra))
suppressMessages(library(reshape2))
suppressMessages(library(nortest))
suppressMessages(library(ggplot2))
suppressMessages(library(grid))
suppressMessages(library(caret))
```
****

\newpage
# Introducción y descripción de los datasets

En la Práctica 1 de la asginatura de _Tipología y ciclo de vida de los datos_ se creó un proceso _web scraping_ en el que se obtuvieron los datos relacionados a todos los partidos y las estadísticas individuales de todos los jugadores de la actual temporada (2019-2020) de la [\textcolor{blue}{Euroliga}](https://www.euroleague.net/), la máxima competición de clubes de baloncesto de Europa. El objetivo final era contribuir al aumento de explotación de los datos para los equipos europeos y tratar de igualar lo que se realiza en América con las poderosas franquicias de [\textcolor{blue}{NBA}](https://es.nba.com/?gr=www).

Mediante el proceso de obtención de datos realizado en _Python_ que comentamos anteriormente, conseguimos crear dos datasets: el primero contiene los datos generales de un partido (nombre de los equipos, puntuación de cada equipo, fecha y hora del partido) y el segundo contiene más de quince estadísticas individuales para cada jugador por cada partido (puntos, minutos, rebotes, asistencias, ...). Este trabajo está disponible en un repositorio de _GitHub_ al que se puede acceder haciendo click [\textcolor{blue}{aquí}](https://github.com/aarzola-uoc/practica1-tycvd).

El primer dataset (`euroleague_scoreboards.csv`) contiene las siguientes variables:

* **Id:** identificador único de partido.
* **Date:** fecha del partido.
* **HomeTeam:** nombre del equipo local.
* **HomeScore:** puntos anotados por el equipo local.
* **VisitingTeam:** nombre del equipo visitante.
* **VisitingScore:** puntos anotados por el equipo visitante.
* **Link:** enlace a la página web con las estadísticas individuales del partido.

El segundo dataset (`euroleague_stats_per_game.csv`) contiene las siguientes variables:

* **MatchId:** identificador único de partido. 
* **Team:** equipo al que pertenece el jugador. 
* **PlayerNumber:** número del jugador.
* **PlayerName:** nombre del jugador.
* **Min:** minutos jugados.
* **Pts:** puntos anotados.
* **2FG:** tiros de dos (metidos-anotados).
* **3FG:** tiros de tres (metidos-anotados).
* **FT:** tiros libres (metidos-anotados).
* **O:** rebotes ofensivos.
* **D:** rebotes defensivos.
* **T:** rebotes totales.
* **As:** asistencias.
* **St:** recuperaciones.
* **To:** pérdidas.
* **Fv:** tapones a favor.
* **Ag:** tapones en contra.
* **Cm:** faltas cometidas.
* **Rv:** faltas recibidas.
* **PIR:** valoración del jugador.

En esta segunda práctica queremos seguir progresando para lograr el objetivo de igualarnos con la NBA y por ello vamos a utilizar los datasets que hemos mencionado para realizar un análisis estadístico. Este análisis se va a enfocar en analizar las estadísticas globales por partido de cada equipo para tratar de estimar y predecir las victorias de un equipo o definir qué equipos defienden mejor, cuales tienen un mejor ataque y aquellos que tienen una forma de jugar más equilibrada.

Los datasets y el código utilizado para generar el análisis estadístico que se desarrolla a continuación está disponible en el siguiente repositorio de _GitHub_:

* \textcolor{blue}{https://github.com/aarzola-uoc/practica2-tycvd}

****
# Integración y selección de los datos de interés a analizar

Los datos relevantes del primer dataset son exclusivamente los nombres de los equipos y el marcador. Sin embargo, estos datos son posibles calcularlos a partir del segundo dataset, incluso aumentar los datos de equipo ya que son la suma de las estadísticas de todos los jugadores para cada partido.

En base a esto, hemos decidido que se creará un nuevo dataset utilizando código R, a partir del dataset de estadísticas de los jugadores, que tendrá las estadísticas de cada equipo por partido (suma de cada jugador es el total del equipo). El primer dataset se utilizará únicamente como referencia para obtener el equipo oponente de cada partido.

Además vamos a calcular una serie de estadísticos muy interesantes y que permiten un análisis mucho más técnico y útli para los equipos. Estos estadísticos son el ritmo de juego, eficiencia ofensiva/defensiva, porcentaje efectivo de tiros de campo, tasa de rebote y algunos más. La explicación de cada uno de estos estadísticos y su correspondiente fórmula se explicará más adelante.

****
# Limpieza de los datos

El primer paso que tenemos que realizar es cargar los ficheros csv `euroleague_stats_per_game.csv` y `euroleague_scoreboards.csv`. Para ello vamos a utilizar la función `read.csv2` ya que el fichero a cargar está en formato csv español (los separadores son el caracter `;`). Como resultado obtendremos dos objetos `data.frame` que contendrán todos los datos de nuestros dos datasets:

```{r,eval=TRUE,echo=TRUE}
data_scoreboards <- read.csv2('../csv/euroleague_scoreboards.csv', header = TRUE)
data_euroleague <- read.csv2('../csv/euroleague_stats_per_game.csv', header = TRUE)
```

Mostramos los primeros registros de ambos datasets para verificar que los datos se han cargado correctamente:

```{r,eval=TRUE,echo=TRUE}
# Primer dataset (euroleague_scoreboards.csv)
head(data_scoreboards)
```

\newpage
```{r,eval=TRUE,echo=TRUE}
# Segundo dataset (euroleague_stats_per_game.csv)
head(data_euroleague)
```

La variable MatchId es una variable que necesitamos para cruzar ambos datasets. Sin embargo, en el primer dataset, el nombre de esta variable es Id por lo que vamos a homogenizar su nombre:
```{r,eval=TRUE,echo=TRUE}
names(data_scoreboards)[names(data_scoreboards) == "Id"] <- "MatchId"
```

En total disponemos de estadísticas de `r length(table(data_scoreboards$MatchId))` partidos y de `r length(table(data_euroleague$PlayerName))` jugadores diferentes. 

## Elementos vacíos

Los datos vacíos o no definidos pueden presentarse en distintos formatos, normalmente en forma de cadena de caracteres vacía (`""`) o `NA` (_Not Available en inglés_), pero en algunos contextos pueden incluso tomar valores numéricos como 0 o 999. Es fundamental identificar para cada variable los valores que indiquen que existe una pérdida de datos para poder aplicar una solución y que no afecte en la calidad de los análisis estadísticos que se realicen posteriormente.

Procedemos a buscar valores vacíos en nuestro primer dataset:
```{r,eval=TRUE,echo=TRUE}
colSums(is.na(data_scoreboards))
colSums(data_scoreboards=="")
```

Como se puede observar no se ha detectado ningún elemento vacío del tipo `NA` o cadena de caracteres vacía. En el caso de que se haya utilizado valores numéricos fuera del dominio del atributo lo podremos detectar en el análisis de valores extremos.

\newpage
Realizamos el mismo análisis para el segundo dataset. En este caso, como hemos creado nosotros el dataset, sabemos que se ha utilizado el caracter `“-”` para indicar las estadísticas de los jugadores que no han jugado el partido y `“DNP”` (_Did Not Play_) en el atributo de tiempo:

```{r,eval=TRUE,echo=TRUE}
colSums(is.na(data_euroleague))
colSums(data_euroleague=="")
colSums(data_euroleague=="-")
colSums(data_euroleague=="DNP")
```

\newpage
Para solucionar este problema y poder realizar un análisis estadístico en el que se pueda asegurar un nivel alto de calidad de datos, hemos optado por informar todos estos campos con el valor 0:
```{r,eval=TRUE,echo=TRUE}
data_euroleague[is.na(data_euroleague)] <- 0
data_euroleague[data_euroleague=="-"] <- 0
data_euroleague[data_euroleague=="DNP"] <- 0

colSums(is.na(data_euroleague))
colSums(data_euroleague=="")
colSums(data_euroleague=="-")
colSums(data_euroleague=="DNP")
```

Hemos vuelto a buscar elementos vacíos para comprobar que se han solucionado todos los problemas que habíamos detectado y como se puede ver en los fragmentos anteriores se han resuelto todos correctamente.

\newpage
## Tratamiento de variables

El siguiente paso consisten en analizar el tipo de dato que ha asignado R para cada una de nuestras variables al cargar los datasets:

```{r,eval=TRUE,echo=TRUE}
str(data_scoreboards)
```

Para el dataset `data_scoreboards` se han interpretado correctamenta las variables `MatchId`, `HomeScore` y `VisitingTeam` con el tipo de dato `int` ya que son variables cuantitativas discretas, mientras que el resto de variables (`Date`, `HomeTeam` y `VisitingTeam`) que son variables cualitativas nominales, se han interpretado como tipo factor.

Verificamos ahora el segundo dataset:

```{r,eval=TRUE,echo=TRUE}
str(data_euroleague)
```

\newpage
En el segundo dataset vemos que la mayoría de variables se han interpretado como tipo `factor` debido a que muchas contenían elementos vacíos. Como ya hemos solucionado este problema, vamos a proceder a asignar el tipo de dato correspondiente a cada variable:

```{r,eval=TRUE,echo=TRUE}
# Variables cuantitativas discretas
data_euroleague$PlayerNumber <- as.integer(as.character(data_euroleague$PlayerNumber))
data_euroleague$Pts <- as.integer(as.character(data_euroleague$Pts))
data_euroleague$O <- as.integer(as.character(data_euroleague$O))
data_euroleague$D <- as.integer(as.character(data_euroleague$D))
data_euroleague$T <- as.integer(as.character(data_euroleague$T))
data_euroleague$As <- as.integer(as.character(data_euroleague$As))
data_euroleague$St <- as.integer(as.character(data_euroleague$St))
data_euroleague$To <- as.integer(as.character(data_euroleague$To))
data_euroleague$Fv <- as.integer(as.character(data_euroleague$Fv))
data_euroleague$Ag <- as.integer(as.character(data_euroleague$Ag))
data_euroleague$Cm <- as.integer(as.character(data_euroleague$Cm))
data_euroleague$Rv <- as.integer(as.character(data_euroleague$Rv))
data_euroleague$PIR <- as.integer(as.character(data_euroleague$PIR))
```

Verificamos que se han realizado los cambios de tipos de variable:
```{r,eval=TRUE,echo=TRUE}
str(data_euroleague)
```

\newpage
Hemos conseguido limpiar bastante los datos pero aún debemos realizar algunas modificaciones en algunas variables:

* **Min:** la variable minutos la pasaremos a formato decimal.
* **Tiros:** las variables tiros de dos (`X2FG`), tiros de tres (`X3FG`) y tiros libres (`FT`), se encuentran en formato "M/A" donde M es convertidos (_made_) y A intentados (_attempts_). Por cada una de ellas, crearemos por lo tanto dos variables, separando los aciertos de los intentos.

```{r,eval=TRUE,echo=TRUE}
# Modificamos la variable tiempo
levels(data_euroleague$Min) <- c(levels(data_euroleague$Min), "0:00")
data_euroleague$Min[data_euroleague$Min=="0"] <- "0:00"

data_euroleague$Min <- sapply(strsplit(as.character(data_euroleague$Min),":"),
  function(x) {
    x <- as.numeric(x)
    x[1]+x[2]/60
  })
```

```{r,eval=TRUE,echo=TRUE}
# Modificamos la variables tiros de 2
levels(data_euroleague$X2FG) <- c(levels(data_euroleague$X2FG), "0/0")
data_euroleague$X2FG[data_euroleague$X2FG=="0"] <- "0/0"

data_euroleague$x2M <- sapply(strsplit(as.character(data_euroleague$X2FG),"/"),
  function(x) {
    x <- as.integer(x)
    x[1]
  })

data_euroleague$x2A <- sapply(strsplit(as.character(data_euroleague$X2FG),"/"),
  function(x) {
    x <- as.integer(x)
    x[2]
  })

data_euroleague$X2FG <- NULL
```

```{r,eval=TRUE,echo=TRUE}
# Modificamos la variables tiros de 3
levels(data_euroleague$X3FG) <- c(levels(data_euroleague$X3FG), "0/0")
data_euroleague$X3FG[data_euroleague$X3FG=="0"] <- "0/0"

data_euroleague$x3M <- sapply(strsplit(as.character(data_euroleague$X3FG),"/"),
  function(x) {
    x <- as.integer(x)
    x[1]
  })

data_euroleague$x3A <- sapply(strsplit(as.character(data_euroleague$X3FG),"/"),
  function(x) {
    x <- as.integer(x)
    x[2]
  })

data_euroleague$X3FG <- NULL
```

\newpage
```{r,eval=TRUE,echo=TRUE}
# Modificamos la variables tiros libres
levels(data_euroleague$FT) <- c(levels(data_euroleague$FT), "0/0")
data_euroleague$FT[data_euroleague$FT=="0"] <- "0/0"

data_euroleague$FTM <- sapply(strsplit(as.character(data_euroleague$FT),"/"),
  function(x) {
    x <- as.integer(x)
    x[1]
  })

data_euroleague$FTA <- sapply(strsplit(as.character(data_euroleague$FT),"/"),
  function(x) {
    x <- as.integer(x)
    x[2]
  })

data_euroleague$FT <- NULL
```

Realizamos la última comprobación de los tipos de datos de las variables del dataset `data_euroleague`:
```{r,eval=TRUE,echo=TRUE}
sapply(data_euroleague, function(x) class(x))
```

Por tanto, el resumen es el siguiente:

* Variables cualitativas nominales: `Team`, `PlayerName` (tipo `factor`).
* Variables cuantitativas discretas: `MatchId`, `PlayerNumber`, `Pts`, `O`, `D`, `T`, `As`, `St`, `To`, `Fv`, `Ag`, `Cm`, `Rv`, `PIR`, `x2M`, `x2A`, `x3M`, `x3A`, `FTM`, `FTA` (tipo `integer`).
* Variables cuantitativas continuas: `Min` (tipo `numeric`).

\newpage
## Agregación de datos

Como previamente comentamos en el [\textcolor{blue}{apartado}](#integración-y-selección-de-los-datos-de-interés-a-analizar) de integración y selección de datos de interés, la idea principal es crear un nuevo dataset que agrupe las estadísticas para cada equipo y partido. Por tanto, el resultado será la suma de las estadísticas de todos los jugadores del equipo para cada partido. Este nuevo dataset se llamará `data_team`:

```{r,eval=TRUE,echo=TRUE}
data_team <- as.data.frame(data_euroleague %>% group_by(Team, MatchId) %>%
  select_if(is.numeric) %>%
  summarise_each(list(sum)))

data_team[c("PlayerNumber")] <- NULL
```

Mostramos los primeros registros de este nuevo dataset:
```{r,eval=TRUE,echo=TRUE}
head(data_team)
```

A primera vista este dataset se ha creado correctamente. Como prueba de la calidad de los datos y del proceso de transformación podemos comprobar que los minutos de los partidos son correctos:

`5 jugadores * 10 mintuos * 4 cuartos = 200 minutos`

Para los partidos con prórroga se deben sumar 5 minutos por cada parte de tiempo extra y multiplicar por los 5 jugadores. Por eso vemos partidos con 225 minutos.

\newpage
## Identificación y tratamiento de valores extremos

Los valores extremos (_extreme scores_ o _outliers_) son aquellos datos que se encuentran muy alejados de la distribución normal de una variable o población, normalmente 3 desviaciones estándar con respecto a la media. Para encontrar estos valores extremos se utiliza los diagramas de cajas o _boxplot_, que permiten identificar si existen valores extremos para una determinada variable. Crearemos uno de estos diagramas para cada variable cuantitativa de nuestro dataset de estadísticas de equipo:

```{r,eval=TRUE,echo=TRUE}
par(mfrow = c(2,2))
for (i in c(seq(3,6))) {
  outlier <- boxplot(data_team[,i], main = colnames(data_team)[i], horizontal = TRUE)
  assign(paste("outlier", i, sep = "."), outlier)
}
par(mfrow = c(1,1))
```

```{r,eval=TRUE,echo=TRUE}
# Valores extremos de la variable Min
outlier.3$out
```

```{r,eval=TRUE,echo=TRUE}
# Valores extremos de la variable Pts
outlier.4$out
```

```{r,eval=TRUE,echo=TRUE}
# Valores extremos de la variable O
outlier.5$out
```

```{r,eval=TRUE,echo=TRUE}
# Valores extremos de la variable D
outlier.6$out
```

\newpage
```{r,eval=TRUE,echo=TRUE}
par(mfrow = c(2,2))
for (i in c(seq(7,10))) {
  outlier <- boxplot(data_team[,i], main = colnames(data_team)[i], horizontal = TRUE)
  assign(paste("outlier", i, sep = "."), outlier)
}
par(mfrow = c(1,1))
```

```{r,eval=TRUE,echo=TRUE}
# Valores extremos de la variable T
outlier.7$out
```

```{r,eval=TRUE,echo=TRUE}
# Valores extremos de la variable As
outlier.8$out
```

```{r,eval=TRUE,echo=TRUE}
# Valores extremos de la variable St
outlier.9$out
```

```{r,eval=TRUE,echo=TRUE}
# Valores extremos de la variable To
outlier.10$out
```

\newpage
```{r,eval=TRUE,echo=TRUE}
par(mfrow = c(2,2))
for (i in c(seq(11,14))) {
  outlier <- boxplot(data_team[,i], main = colnames(data_team)[i], horizontal = TRUE)
  assign(paste("outlier", i, sep = "."), outlier)
}
par(mfrow = c(1,1))
```

```{r,eval=TRUE,echo=TRUE}
# Valores extremos de la variable Rv
outlier.14$out
```

\newpage
```{r,eval=TRUE,echo=TRUE}
par(mfrow = c(2,2))
for (i in c(seq(15,18))) {
  outlier <- boxplot(data_team[,i], main = colnames(data_team)[i], horizontal = TRUE)
  assign(paste("outlier", i, sep = "."), outlier)
}
par(mfrow = c(1,1))
```

```{r,eval=TRUE,echo=TRUE}
# Valores extremos de la variable x2M
outlier.16$out
```

```{r,eval=TRUE,echo=TRUE}
# Valores extremos de la variable x2A
outlier.17$out
```

```{r,eval=TRUE,echo=TRUE}
# Valores extremos de la variable x3M
outlier.18$out
```

\newpage
```{r,eval=TRUE,echo=TRUE}
par(mfrow = c(2,2))
for (i in c(seq(19,21))) {
  outlier <- boxplot(data_team[,i], main = colnames(data_team)[i], horizontal = TRUE)
  assign(paste("outlier", i, sep = "."), outlier)
}
par(mfrow = c(1,1))
```


```{r,eval=TRUE,echo=TRUE}
# Valores extremos de la variable x3A
outlier.19$out
```

```{r,eval=TRUE,echo=TRUE}
# Valores extremos de la variable FTM
outlier.20$out
```

```{r,eval=TRUE,echo=TRUE}
# Valores extremos de la variable FTA
outlier.21$out
```

\newpage
Mediante los gráficos de caja anteriores hemos obtenido la siguiente información:

* **Variables sin _outliers_:** `Fv`, `Ag`, `Cm` y `PIR`.
* **Variables con _outliers_:** `Min`, `Pts`, `O`, `D`, `T`, `As`, `St`, `To`, `Rv`, `x2M`, `x2A`, `x3M`, `x3A`, `FTM` y `FTA`.

Tras revisar todos individualmente todos los valores extremos hemos determinado que todos ellos son valores posibles y que están dentro del rango del atributo, por lo que se considerarán como valores legítimos y se contemplarán en los análisis posteriores.

Un ejemplo claro es el de la variable que representa los minutos, donde la mayoría de partidos duran 200 minutos con excepción de los que tienen prórroga, como ya explicamos anteriormente cuando creamos el dataset con las estadísticas de los equipos. 

Otro ejemplo de valores extremos legítimos serían los de la variable que representa los puntos obtenidos en un partido por un equipo: 113, 109, 111. Por lo que vemos, en la Euroliga podemos considerar como fuera de lo habitual que un equipo meta más de 110 puntos. Si realizaramos el mismo análisis sobre equipos de la NBA veríamos que este valor cambiaría bastante ya que en la liga americana es más habitual que los equipos consigan marcadores más abultados. Si hubiésemos obtenido un _outlier_ de 200 o 300 para la variable puntos si hubiésemos tenido que eliminar ese registro o revisar si se produjo un error en el proceso de _web scraping_ o en la carga de datos, ya que sería un dato que se aleja bastante de la normalidad.

****
\newpage
# Enriquecimiento de los datos
## Datos del oponente.
Durante un encuentro de baloncesto, es tan importante medir lo que tú equipo ha hecho como lo que tú equipo ha recibido. Por lo tanto, buscamos enriquecer la información por partido de cada equipo añadiendo la información del oponente. Para ello, utilizaremos el dataset `data_scoreboards` para completar así los registros:

```{r,eval=TRUE,echo=TRUE}
names(data_scoreboards)[names(data_scoreboards) == "Id"] <- "MatchId"
names(data_scoreboards)[names(data_scoreboards) == "HomeTeam"] <- "Team"
names(data_scoreboards)[names(data_scoreboards) == "VisitingTeam"] <- "Opponent"

df_1 <- merge(data_team, data_scoreboards, by=c("MatchId","Team"))
df_1["Local"] <- 1

names(data_scoreboards)[names(data_scoreboards) == "Team"] <- "HomeTeam"
names(data_scoreboards)[names(data_scoreboards) == "Opponent"] <- "Team"
names(data_scoreboards)[names(data_scoreboards) == "HomeTeam"] <- "Opponent"
df_2 <- merge(data_team, data_scoreboards, by=c("MatchId","Team"))
df_2["Local"] <- 0

data_team <- bind_rows(df_1,df_2)

data_team[c("Date")] <- NULL
data_team[c("HomeScore")] <- NULL
data_team[c("VisitingScore")] <- NULL
data_team[c("Link")] <- NULL

data_team2 <- data_team [c("MatchId","Team","Min","Pts","O","D","T","As","St","To",
                           "Fv","Ag","Cm","Rv","PIR","x2M","x2A","x3M","x3A","FTM",
                           "FTA")]

names(data_team2)[names(data_team2) == "Pts"] <- "Pts_Opp"
names(data_team2)[names(data_team2) == "O"] <- "O_Opp"
names(data_team2)[names(data_team2) == "D"] <- "D_Opp"
names(data_team2)[names(data_team2) == "T"] <- "T_Opp"
names(data_team2)[names(data_team2) == "As"] <- "As_Opp"
names(data_team2)[names(data_team2) == "St"] <- "St_Opp"
names(data_team2)[names(data_team2) == "To"] <- "To_Opp"
names(data_team2)[names(data_team2) == "Fv"] <- "Fv_Opp"
names(data_team2)[names(data_team2) == "Ag"] <- "Ag_Opp"
names(data_team2)[names(data_team2) == "Cm"] <- "Cm_Opp"
names(data_team2)[names(data_team2) == "Rv"] <- "Rv_Opp"
names(data_team2)[names(data_team2) == "PIR"] <- "PIR_Opp"
names(data_team2)[names(data_team2) == "x2M"] <- "x2M_Opp"
names(data_team2)[names(data_team2) == "x2A"] <- "x2A_Opp"
names(data_team2)[names(data_team2) == "x3M"] <- "x3M_Opp"
names(data_team2)[names(data_team2) == "x3A"] <- "x3A_Opp"
names(data_team2)[names(data_team2) == "FTM"] <- "FTM_Opp"
names(data_team2)[names(data_team2) == "FTA"] <- "FTA_Opp"

data_teamopp <- merge(data_team, data_team2, by.x=c("MatchId","Opponent"),  
                      by.y=c("MatchId","Team"))
data_teamopp["y.min"]<-NULL
```

\newpage
## Creación de nuevas métricas de equipo

Durante los últimos años, se ha dado una vuelta al análisis de la estadísticas en baloncesto. Como los diferentes equipos, de acuerdo a su estilo, juegan a distintos ritmos, no podemos usar los promedios por partido para compararlos.
Para poder lograr las comparaciones hay definir el concepto de las posesiones, que es la base de estos cálculos. El basket es un juego en el que ambos equipos se alternan la posesión de la pelota. El equipo que aproveche mejor sus posesiones será el equipo ganador.
Se entiende que una posesión termina con un tiro al aro, una pérdida de balón o un tiro libre. Allí el balón pasa al rival y la posesión se termina.
¿Qué ocurre si el equipo falla el tiro de campo pero captura el rebote ofensivo? Hoy por hoy, la mayoría de los estadistas de baloncesto consideran que no se le debe anotar una nueva posesión al equipo, sino considerar que la misma posesión continúa.   

Para tener en cuenta lo anteriormente mencionado, a continuación definiremos nuevas métricas.

### Ritmo (Pace)

Nos da una idea del ritmo de juego del equipo, expresado en cantidad de posesiones por juego que utiliza. Hay equipos que corren más y equipos que prefieren el juego estático. Por eso las estadísticas por juego no sirven para comparar equipos. Las posesiones se calculan con la siguiente fórmula:

\[
  \makebox[\linewidth]{$Pos = FGA - OR + TO + (FTA*0.4)$}
\]

Donde:

* Pos: posesiones
* FGA (field goal attempts): lanzamientos de campo (tanto de 2 y de 3)
* OR (ofensive rebounds): rebotes ofensivos
* TO (turnovers): pelotas perdidas
* FTA (free throw attempts): tiros libres lanzados \newline

```{r,eval=TRUE,echo=TRUE}
data_teamopp["Poss"] <- data_teamopp["x2A"] + data_teamopp["x3A"] - 
  data_teamopp["O"] + data_teamopp["To"] + (0.4*data_teamopp["FTA"])
```

### Eficiencia ofensiva (Rating ofensivo)

Habitualmente se evalúa la ofensiva en puntos convertidos por juego, lo cual es una manera un tanto absurda. Si pensamos el juego como una serie de posesiones, el equipo que más puntos convierta en sus posesiones, será el más efectivo. Se multiplica por 100 para expresar los puntos cada 100 posesiones, y no manejar números con decimales. Así:

\[
  \makebox[\linewidth]{$Offensive Rating = (puntos/posesiones)*100$}
\]

```{r,eval=TRUE,echo=TRUE}
data_teamopp ["Off_Rat"] <- +data_teamopp["Pts"]/data_teamopp["Poss"]
```

\newpage
### Eficiencia defensiva (Rating defensivo)

Así como medimos la eficiencia ofensiva en base a puntos convertidos cada 100 posesiones, podemos medir la defensa en base a puntos recibidos (o puntos del oponente) cada 100 posesiones del equipo contrario.

\[
  \makebox[\linewidth]{$Defensive Rating = (puntos_{oponente}/posesiones)*100$}
\]

```{r,eval=TRUE,echo=TRUE}
data_teamopp ["Def_Rat"] <- +data_teamopp["Pts_Opp"]/data_teamopp["Poss"]
```

### Porcentaje efectivo de tiros de campo (eFG%)

Esta estadística ajusta los tiros de campo dandole el valor extra (un punto más) a los triples. Esto corrige el FG% común que subestima a los triples. Por ejemplo, si un jugador ha hecho 2/5 en T2 y 1/4 en T3, habrá convertido 3/9 en tiros de campo (33%), que es similar a si hubiera metido 3/5 de T2 y 0/4 en T3. Sin embargo, en el primer supuesto ha conseguido más puntos para el equipo. Así, el eFG% del primero será 44.4% que se ajusta más a la realidad. La fórmula, por tanto es:

\[
  \makebox[\linewidth]{$eFG\% = \frac{(FGM + 0.5*3PM)}{FGA}$}
\]

Donde:

* FGM (field goal made): tiros de campo convertidos.
* 3PM (3 points made): triples convertidos.
* FGA (field goal attempts): tiros de campo intentados.

```{r,eval=TRUE,echo=TRUE}
data_teamopp ["eFG"] <- (data_teamopp["x2M"] + 1.5*data_teamopp["x3M"]) /
  (data_teamopp["x2A"] + data_teamopp["x3A"])

data_teamopp ["eFG_Opp"] <- (data_teamopp["x2M_Opp"] + 1.5*data_teamopp["x3M_Opp"]) /
  (data_teamopp["x2A_Opp"]+data_teamopp["x3A_Opp"])
```

### Lanzamientos reales (True Shooting)

Esta métrica tiene en cuenta los dobles, triples y tiros libres, para dar una idea de cómo tira el jugador globalmente. Ejemplo: en la 2009-2010, Martin Leiva quedó #8 en FG% con 58,72. Pero si le agregamos los libres, cae al puesto #91 con 54.8%. La fórmula es:

\[
  \makebox[\linewidth]{$TS = \frac{puntos}{2*(FGA+0.44*FTA)}$}
\]

Donde:

* FGA (field goal attempts): lanzamientos de cancha intentados
* FTA (free throw attempts): tiros libres intentados

```{r,eval=TRUE,echo=TRUE}
data_teamopp ["TS"] <- data_teamopp["Pts"] /
  (data_teamopp["x2A"] + data_teamopp["x3A"] + 0.44*data_teamopp["FTA"])

data_teamopp ["TS_Opp"] <- data_teamopp["Pts_Opp"] /
  (data_teamopp["x2A_Opp"] + data_teamopp["x3A_Opp"] + 0.44*data_teamopp["FTA_Opp"])
```

\newpage
### Rebotes

Los rebotes totales de un equipo son de poco valor. Capturar un rebote ofensivo requiere diferentes habilidades que capturar uno defensivo, por lo que deben analizarse por separado.

Tener en cuenta el número absoluto de rebotes conseguidos, o el promedio de rebotes por partido, nos puede llevar a errores, ya que los rebotes disponibles dependen de la efectividad: si un equipo falla poco, hay pocos rebotes por tomar. 

Ejemplo: el equipo A obtuvo en un partido 20 rebotes defensivos. Si  el equipo B falló 30 lanzamientos (o sea que hubo 30 rebotes en el aro defensivo de A) entonces A capturó 66% de los rebotes en su aro (20 de 30). Pero si B erró 25 tiros, A tomó 80% de los rebotes (20 de 25).

Esto hace que, para evaluarlo correctamente, definamos: DR% como porcentaje de rebotes defensivos y OR% porcentaje de rebotes ofensivos.  

#### Tasa de rebotes ofensivos

\[
  \makebox[\linewidth]{$\% de rebotes ofensivos = [OR/(OR+op DR)]*100$}
\]

Donde:

* OR (ofensive rebounds): rebotes ofensivos.
* Op DR (oponent defensive rebounds): rebotes defensivos del rival.

#### Tasa de rebotes defensivos

\[
  \makebox[\linewidth]{$\% de rebotes defensivos = [DR/(DR+op OR)]*100$}
\]

Donde:

* DR (defensive rebounds): rebotes defensivos.
* Op OR (oponent ofensive rebounds): rebotes ofensivos del rival.

```{r,eval=TRUE,echo=TRUE}
data_teamopp ["Off_Reb"] <- data_teamopp["O"] /  (data_teamopp["O"]+data_teamopp["D_Opp"])

data_teamopp ["Def_Reb"] <- data_teamopp["D"] /  (data_teamopp["D"]+data_teamopp["O_Opp"])
```

### Porcentaje de asistencias y pérdidas

Al igual que con los rebotes y otras estadísitcas, las asistencias por juego no son un buen parámetro, ya que dependen del ritmo de juego. Es más preciso calcular las asistencias expresadas en posesiones terminan con una pérdida de balón. Habitualmente expresado en porcentaje.

### Porcentaje de asistencias

Se calculan mediante la siguiente fórmula:

\[
  \makebox[\linewidth]{$\% de asistencias = (asistencias/posesiones)*100$}
\]

```{r,eval=TRUE,echo=TRUE}
data_teamopp ["Pct_ass"] <- data_teamopp["As"] /  (data_teamopp["Poss"])

data_teamopp ["Pct_ass_opp"] <- data_teamopp["As_Opp"] /  (data_teamopp["Poss"])
```

\newpage
#### Porcentaje de pérdidas

Lo mismo ocurre con las pérdidas. No es lo mismo perder 10 pelotas en un partido en que hubo 100 posesiones, que en uno que hubo 80. Por eso es mejor calcular las pérdidas cada 100 posesiones. El valor ideal depende del ritmo de juego, pero podríamos decir que el objetivo sería tener menos de 15% de TO y provocar en el oponente más de 15%. La fórmula es:

\[
  \makebox[\linewidth]{$\% de pérdidas = (pelotas pérdidas/posesiones)*100$}
\]

```{r,eval=TRUE,echo=TRUE}
data_teamopp ["Pct_To"] <- data_teamopp["To"] /  (data_teamopp["Poss"])

data_teamopp ["Pct_To_opp"] <- data_teamopp["To_Opp"] /  (data_teamopp["Poss"])
```

#### Tiros libres, respecto a tiros de campo (FTM/FGA)

Es simplemente una manera de expresar el número de veces que un equipo va a la línea y cuántas veces envía al oponente a la línea. Esta considerado (junto con el _effective field goal percentage_, la tasa de rebotes ofensivos y la tasa de pérdidas) uno de los cuatro factores con los que se miden los partidos. La fórmula es:

\[
  \makebox[\linewidth]{$Libres por lanzamientos de cancha = (libres convertidos/tiros de cancha intentados) * 100$}
\]

```{r,eval=TRUE,echo=TRUE}
data_teamopp["FTR"] <- data_teamopp["FTM"] /  (data_teamopp["x2A"]+ data_teamopp["x3A"])

data_teamopp["FTR_opp"] <- data_teamopp["FTM_Opp"] /
  (data_teamopp["x2A_Opp"]+ data_teamopp["x3A_Opp"])
```

### Victoria

Otro aspecto fundamental en un partido de baloncesto y que necesitaremos para realizar los análisis es saber quién ganó el partido. Esto se puede obtener simplemente comparando el resultado final y determinando quién metió más puntos:

```{r,eval=TRUE,echo=TRUE}
data_teamopp$Win <- ifelse(data_teamopp$Pts>=data_teamopp$Pts_Opp, 1, 0) 
```

### Triunfos esperados (Expected wins)

Para ganar, obviamente hay que meter más puntos que el rival. Existe un cálculo (comprobado en la NBA, baloncesto FIBA y universitario) que de acuerdo a los puntos convertidos y recibidos, se puede estimar la cantidad de partidos que habría que haber ganado. Suele correlacionar muy bien con la realidad. 

\[
  \makebox[\linewidth]{$Triunfos esperados = eficiencia ofensiva^{14}/(eficiencia ofensiva^{14}+eficiencia defensiva^{14})$}
\]


```{r,eval=TRUE,echo=TRUE}
data_teamopp ["Expected_Wins"] <- data_teamopp["Off_Rat"]^14 /
  (data_teamopp["Off_Rat"]^14+data_teamopp["Def_Rat"]^14)
```

\newpage
## Creación de nuevas métricas de jugadores

Una vez definidas los nuevos estadísticos para el datser de equipos, realizaremos el mismo trabajo para el dataset de jugadores. De esta forma contaremos con nuevas variables que permitan determinar con mayor precisión la calidad y participación de los jugadores en un partido.

Para obtener estos estadísticos nos hemos basado en un artículo de la página web **Bleacher Report** donde se explican métricas y estadísticas avanzadas para la NBA. Se puede acceder al artículo haciendo [\textcolor{blue}{click aquí}](https://bleacherreport.com/articles/1039116-understanding-the-nba-explaining-advanced-offensive-stats-and-metrics).

Como necesitaremos datos del equipo, de nuevo el primer paso es enriquecer la tabla cruzando los datos de players y de equipos por partidos.
```{r,eval=TRUE,echo=TRUE}
data_players <- merge(data_euroleague, data_teamopp, by=c("MatchId","Team"))
```

### Assist Percentage (AST%)

\[
  \makebox[\linewidth]{$A/(((MP/(TMP/5))*TFG)-FG)$}
\]


Donde: 

* A: Assists.
* MP: Minutes Played.
* TMP: Team Minutes Played.
* TFG: Team Field Goals. 
* FG:Field Goals.

Explanation

Leading off this guide to advanced offensive metrics in the NBA is perhaps the most basic of the stats: assist percentage. I say perhaps "basic" because it's one of many tempo-free stats, or stats adjusted for pace and volume. 

While assists in themselves are kind of useful to look at, assist percentage is a much better statistic to cite when trying to make a case for a player's skill in the passing department. Assist stats can be padded by two things: the amount of time that a player is on the court and the pace at which his team plays.

A player on a fast-paced team like the Miami Heat or Washington Wizards is going to have more offensive opportunities to rack up counting stats, leading to elevated numbers of assists per game and assists per minute (which are also a better way of looking at assists than just assists by themselves).

Similarly, a player who plays 35 minutes per game is going to have more opportunities to generate assists than a player on the court for 20 minutes per game. It may seem like common sense that averaging 10 assists per game in 20 minutes of action per contest is more impressive than averaging 10 assists per game in 35 minutes of action per contest, but that distinction is lost when only assists per game is cited.    

Because assist percentage is free from the effects of pace and volume, it's a better indication of how effective a player is at racking up the dimes during each and every one of the team's possessions. 

The stat essentially estimates (note: estimates, not calculates) what percentage of made shots by teammates were assisted by a player while he was on the floor.

Limitations

Without looking at play-by-play data, the best this stat can do is provide an estimate of the aforementioned percentage it is meant to calculate. Additionally, there is no way to measure and give credit for good passes that resulted in missed open looks.

Just as with any assist statistic, a player is at the mercy of the skill of his teammates. 
```{r,eval=TRUE,echo=TRUE}
data_players$Assist_pct <- data_players$As.x/(((data_players$Min/(data_players$Min.x/5))*
                                                 (data_players$x2A.y+data_players$x3A.y))-
                                                (data_players$x2A.x+data_players$x3A.x))
```

### Turnover Percentage (TOV%)

\[
  \makebox[\linewidth]{$100*TO/(FGA+0.44*FTA+TO)$}
\]

Donde:

* TO: Turnovers.
* FGA: Field Goals Attempted.
* FTA: Free Throws Attempted.

Explanation

The second of the offensive tempo-free stats, turnover percentage, is free from the effects of tempo because it isolates the possessions in which the player in question made a box score impact.

Before explaining exactly what this stat does though, I'd like to focus on the parenthetical denominator of the above calculation: (FGA+0.44*FTA+TO). This mathematical expression is the best way of quantifying the number of play results a player was involved in without simply going back through every box score and actually counting.

There are three ways that a player can be involved in the end result of a possession. They can attempt a field goal (regardless of whether it's a two-pointer or a three-pointer), they can end up on the foul line or they can turn the ball over. However, simply summing those three results does not provide the number of possessions because shooters can attempt either one, two or three free throws on any given possession. 

Box scores don't explain how many shots a player was fouled on, so we have no idea of knowing which fouls resulted in and-ones (for example) without looking through historical play-by-play data.

Just trust on this one (I've read the studies and they're too complicated to explain in a short space) and accept the fact that the 0.44 multiplier is the best way of estimating the total number of possessions a player is involved in. 

So now that we've got that out of the way, all this stat really does is calculate the number of turnovers a player will make in 100 individual plays.

Turnovers and turnovers per game are both dependent once more on pace of play and the amount of time a player spends on the court. This rate statistic eliminates those detriments and focuses solely on the percentage of times a player turns the ball over compared to the amount of times they're involved in the play.  


Limitations

Turnover percentage still can't factor in the passes that a player makes that result in non-turnovers (i.e. assists or passes to other players who either miss a shot or don't shoot).

Therefore, it's still a fairly limited stat because it only focuses on the true outcomes of possessions when that player is involved. 

```{r,eval=TRUE,echo=TRUE}
data_players$Turnover_pct<-ifelse((data_players$x2A.x+data_players$x3A.x+
                                     0.44*data_players$FTA.x+data_players$To.x)==0,0,
                                  data_players$To.x/(data_players$x2A.x+
                                                       data_players$x3A.x+
                                                       0.44*data_players$FTA.x+
                                                       data_players$To.x))
```

### Offensive Rebound Percentage (ORB%)

\[
  \makebox[\linewidth]{$100*(ORB*(TMP/5)/(MP*(TORB+ODRB))$}
\]

Donde:

* ORB: Offensive Rebounds.
* TMP: Team Minutes Played.
* MP: Minutes Played.
* TORB: Team Offensive Rebounds.
* ODRB: Opponents Defensive Rebound.


Explanation

Whenever a shot clanks off the rim, there are four possible outcomes: The ball could go out of bounds and be counted as a defensive team rebound; the ball could bounce of a defensive player and go out of bounds to be counted as an offensive team rebound; the ball could be pulled down by a defensive player and be counted as a defensive rebound; or the ball could be pulled down by an offensive player and be counted as an offensive rebound.

If you add up all four of those results, you account for all of the potential rebounds in a game.

Offensive rebound percentage calculates the percentage of available offensive rebounds that a player grabs while he's on the court.

This is the last of the commonly-used offensive tempo-free rate stats and much like the previous two, it doesn't account for pace or volume.   


Limitations

Once more, it's too much trouble to go back and retroactively look at all historical box scores. No one really wants to do that.

Therefore, this is merely an estimate, albeit an accurate one.  


De manera análoga, definimos el porcentaje de rebotes defensivos.
```{r,eval=TRUE,echo=TRUE}
data_players$Offensive_Reb_pct <- data_players$O.x*(data_players$Min.x/5)/
  (data_players$Min*(data_players$O.y+data_players$D_Opp))

data_players$Defensive_Reb_pct <- data_players$D.x*(data_players$Min.x/5)/
  (data_players$Min*(data_players$D.y+data_players$O_Opp))
```

### Effective Field-Goal Percentage (eFG%)

\[
  \makebox[\linewidth]{$(FG+0.5*3P)/FGA$}
\]

Donde:

* FG: Field Goals.
* 3P: Three-Pointers.
* FGA: Field-Goal Attempts.

Explanation

Field-goal percentage (FG%) was once one of the better stats for estimating shooting ability up until the popularization of effective field-goal percentage in the 1990s. 

The only difference between the two stats is that three-pointers are weighted more heavily in eFG%. Seeing as three-pointers are worth three points and two-pointers are worth two points, this makes sense.

That may be the most ridiculously obvious sentence I've ever written. 

Don't make the mistake of thinking that the multiplier in front of three-pointers should be 1.5 though. Essentially, it is in the above formula because three-pointers are counted one time in field goals and another 0.5 times on the other side of the addition sign.

So, as for the merits of effective field-goal percentage, tell me which of the following players you'd rather have:

Player A attempts 10 shots from the field, all from within the three-point arc, and drills five of them.

Player B attempts 10 shots from the field, all from outside the three-point arc, and drills five of them.

Player A, who was responsible for 10 points, has a FG% of 50 percent, just like Player B, who was responsible for 15 points, despite shooting the same number of times. However, Player A's eFG% was still 50 percent while Player B's was a much better 75 percent.    


Limitations

While I like eFG% as a stat, there is still a measure of shooting that is significantly better. If for nothing else, that's because it takes free-throw shooting into account as well, unlike eFG%. 

You'll see what that stat is pretty soon. 

Also, the penalty for missing a three-pointer is the same as the penalty for missing a two-pointer because all attempts are weighted the same. 

```{r,eval=TRUE,echo=TRUE}
data_players$eFG_player<-ifelse((data_players$x3A.x+data_players$x2A.x)==0,0,
                                (data_players$x2M.x+1.5*data_players$x3M.x)/
                                  (data_players$x3A.x+data_players$x2A.x))
```

### True Shooting Percentage (TS%)

\[
  \makebox[\linewidth]{$PT/(2*(FGA+0.44*FTA))$}
\]

Donde:

* PT: Points.
* FGA: Field-Goal Attempts.
* FTA: Free-Throw Attempts.


Explanation

There are three ways that an NBA player can score: three-pointers, two-pointers and free throws. It just makes sense that the best measure of shooting percentage would take all three of those methods of scoring into account. 

So, does true shooting percentage look at all three?

As you can see by the "Field-Goal Attempts" and "Free-Throw Attempts" in the calculation, TS% clearly at least takes two-pointers and free throws into account. As for the 0.44 multiplier, the same reasoning applies as did for turnover percentage. You can find the full explanation on that slide.

Three-pointers are a little harder to find in the formula, but they're still there, hidden within the word "Points." The maximum TS% is actually 150 percent and can only be achieved if a player hits each and every one of his shots and they're all from downtown. For example, if a player goes 1-for-1 and his only shot is a three-pointer, the formula will read and simplify as follows: 3/(2*1+0.44*0)) = 3/2 = 1.5.

Because this stat does take everything into account, it's easily the best measure of shooting ability we have. Just for the record, it can also be called adjusted shooting percentage, effective shooting percentage, effective percentage, points per shot attempted and scoring efficiency.  


Limitations

Other than only accounting for shooting ability, and thereby not qualifying as an overall evaluation of a player's offensive ability, the only true limitation of TS% is that it's possible (although extremely unlikely) to have a TS% of over 100 percent.

Also, just like with effective field-goal percentage, all missed attempts count the same.  

```{r,eval=TRUE,echo=TRUE}
data_players$TS_player <- ifelse((2*(data_players$x3A.x+data_players$x2A.x+
                                  0.44*data_players$FTA.x))==0,0,data_players$Pts.x/
                                   (2*(data_players$x3A.x+data_players$x2A.x
                                       +0.44*data_players$FTA.x)))
```


### Usage Rate (USG%)

\[
  \makebox[\linewidth]{$100*((FGA+0.44*FTA+TO)*(TMP/5))/(MP*(TFGA+0.44*TFTA+TTO))$}
\]


Where FGA=Field-Goal Attempts, FTA=Free-Throw Attempts, TO=Turnovers, TMP=Team Minutes Played, MP=Minutes Played, TFGA=Team Field-Goal Attempts, TFTA=Team Free-Throw Attempts, TTO=Team Turnovers


Explanation

This may be the most complicated looking calculation yet, but the concept behind it is really quite simple. Usage rate calculates what percentage of team plays a player was involved in while he was on the floor, provided that the play ends in one of the three true results: field-goal attempt, free-throw attempt or turnover.

On average, a player will have a usage rate of 20 percent. Think about it and it will make perfect sense. 

Limitations

Only the true outcomes are measured here, so there is quite a bit left out. For example, a player like Ricky Rubio, who prefers to pass more than shoot will have a much lower USG% than a player who prefers to shoot.

Yet, a player who passes the ball is still involved in a possession in my mind.   

```{r}
data_players$Usage_rate <- 
(data_players$x3A.x+data_players$x2A.x+0.44*data_players$FTA.x+data_players$To.x)*
  (data_players$Min.x/5)/(data_players$Min*(data_players$x3A.y+data_players$x2A.y+
                                              0.44*data_players$FTA.y+data_players$To.y))

```

### Points Per Possession (PPP)

\[
  \makebox[\linewidth]{$PT/(FGA+0.44*FTA+TO)$}
\]

Donde:

* PT: Points.
* FGA: Field-Goal Attempts.
* FTA: Free-Throw Attempts.
* TO: Turnovers.


Explanation 

The numerator is clearly represented by the word "Points." There is really no explanation necessary there. 

Per refers to the division sign. 

We've already seen how possessions can be best estimated by what's written in the above denominator. The full explanation is provided on the turnover percentage slide. 

This stat in its simplest form explains how efficiently a player uses his time with the ball to score. With the help of companies like Synergy, PPP can be further broken down into certain situations like isolation plays, pick-and-roll situations, etc. 


Limitations

This stat only refers to scoring efficiency and there's more than scoring to basketball, even on offense. 

Other than that and the fact that the possessions are estimates, there aren't too many limitations to PPP. 

```{r,eval=TRUE,echo=TRUE}
data_players$Points_per_possesion <-ifelse((data_players$x3A.x+data_players$x2A.x+
                                              0.44*data_players$FTA.x+data_players$To.x)==0,
                                           0,data_players$Pts.x/
                                             (data_players$x3A.x+data_players$x2A.x+
                                                0.44*data_players$FTA.x+data_players$To.x))
```

### Free Throw Rate

Completamos los estadísticos con los encontrados en:
https://www.fromtherumbleseat.com/pages/advanced-basketball-statistics-formula-sheet

```{r,eval=TRUE,echo=TRUE}
data_players$FTR_player <- ifelse((data_players$x2A.x+data_players$x3A.x)==0,
                                  0,data_players$FTM.x/
                                    (data_players$x2A.x+data_players$x3A.x))
```

### Hollinger Assist Ratio (hAST%)

\[
  \makebox[\linewidth]{$hAST\% = AST / (FGA + .44 * FTA + AST + TOV)$}
\]

Think of Carmelo Anthony for this statistic, it is a "ball stopper" stat. This divides the number of assists a player has by the number of offensive possessions that end in that player's hands.

```{r,eval=TRUE,echo=TRUE}
data_players$Hollinger_Assist_ratio <- ifelse((data_players$x2A.x+data_players$x3A.x+0.44*
                                                 data_players$FTA.x+data_players$As.x+
                                                 data_players$To.x)==0,0,
                                              data_players$As.x/
                                                (data_players$x2A.x+data_players$x3A.x+
                                                   0.44*data_players$FTA.x+
                                                   data_players$As.x+
                                                   data_players$To.x))
```

### Pomeroy Assist Ratio (pAST%)


\[
  \makebox[\linewidth]{$pAST\% = AST / (((MP / (TmMP / 5)) * TmFG ) - FG)$}
\]
    

The percentage of teammate baskets a player assisted on while he was on the court - my preferred Assists statistic

```{r,eval=TRUE,echo=TRUE}
data_players$Pomeroy_Assist_ratio <- data_players$As.x/
  (((data_players$Min / (data_players$Min.x / 5)) * 
      (data_players$x3A.y+data_players$x2A.y) ) - 
     (data_players$x3A.x+data_players$x2A.x))
```

### Steal Percentage (STL%)

\[
  \makebox[\linewidth]{$STL\% = STL / ((MP / (TmMP / 5)) * OppPoss)$}
\]
    

Percent of opponent possessions in which a player gets a steal

```{r,eval=TRUE,echo=TRUE}
data_players$Steal_pct<-data_players$St.x/
  (data_players$Min/(data_players$Min.x/5)*(data_players$Poss))
```

### Block Percentage (BLK%)

\[
  \makebox[\linewidth]{$BLK\% = BLK / ((MP / (TmMP / 5 )) * (OppFGA - Opp3PA))$}
\]

Percent of opponents' "blockable" shots that the player blocks (removes 3 point shots, as these are generally not "blockable", somewhat arbitrary since you see these blocked and a mid range jump shot is just as unlikely to be blocked, yet is included in the sample)

```{r,eval=TRUE,echo=TRUE}
data_players$Block_pct<-data_players$Fv.x/
  (data_players$Min/(data_players$Min.x/5)*(data_players$x2A_Opp))

data_players$ThreePointers_ratio <- ifelse((data_players$x3A.x+data_players$x2A.x)==0
                                           ,0,data_players$x3A.x/
                                             (data_players$x3A.x+
                                                data_players$x2A.x))
```

****

\newpage
# Análisis de los datos
## Comprobación de la normalidad y homogeneidad de la varianza

Para la comprobación de que los valores que toman nuestras variables cuantitativas provienen de una población distribuida normalmente, utilizaremos la prueba de normalidad de _Anderson-Darling_.

Así, se comprueba que para que cada prueba se obtiene un p-valor superior al nivel de significación prefijado $\alpha = 0.05$. Si esto se cumple, entonces se considera que variable en cuestión sigue una distribución normal.

```{r,eval=TRUE,echo=TRUE}
alpha = 0.05
col.names = colnames(data_team)

for (i in 1:ncol(data_team)) {
  if (i == 1) cat("Variables que no siguen una distribución normal:\n")
  if (is.integer(data_team[,i])| is.numeric(data_team[,i])) {
    p_val = ad.test(data_team[,i])$p.value 
    if (p_val < alpha) {
      cat(col.names[i])
      
      # Format output
      if (i < ncol(data_team) - 1) cat(", ")
      if (i %% 3 == 0) cat("\n") 
    }
  } 
}
```

A continuación, estudiamos la homogenidad de varianzas mediante la aplicaicón del test de _Fligner-Killeen_. En este caso, estudiaremos esta homogeneidad en cuanto a los equipos con victoria frente a los equipos con derrota. En el siguiente test, la hipótesis nula consiste en que ambas varianzas son iguales:

```{r,eval=TRUE,echo=TRUE}
fligner.test(Pts ~ Win, data = data_teamopp)
```

Puesto que obtenemos un p-valor superior a 0,05, aceptamos la hipótesis de que las varianzas de ambas muestras son homogéneas.

\newpage
## Regresión lineal para estimar los ratings

Una de las primeras conclusiones a las que hemos llegado es que podemos darnos una idea muy buena de cuál será el rendimiento de un equipo en función del Rating Ofensivo y del Rating Defensivo. 

Pero, ¿Cómo podemos estimar dichos Ratings en base a las variables recogidas en la estadística?

Uno de los primeros estadísticos dedicados al anáisis de los datos para el deporte fue el estadounidense Dean Olliver. Él decía que el rendimiento de un equipo depende de cuatro factores fundamentales anteriormente definidios:
- eFG.
- Offensive Rebounding Percentage. 
- Turnover Percentage.
- Free Throw Rate

Proponemos, por tanto, estimar el rating ofensivo en base a los cuatro factores de ataque y el defensivo en función de los cuatro factores de defensa.

Para ello nos valdremos de una regresión lineal.

**Rating ofensivo en función de los Four Factors de Dean Olliver**

Comencemos pues por el rating ofensivo. El primer paso que daremos para resolver el problema, será el de calcular la correlación entre las variables explicativas.

```{r,eval=TRUE,echo=TRUE}
# Rating de ataque
data_teamopp["Off_Reb_Opp"]<-1-data_teamopp["Def_Reb"]

data_ataque <- data_teamopp[c("Off_Rat","eFG","Off_Reb","Pct_To","FTR")]
corr_ataque <- round(cor(data_ataque),2)
corr_ataque
```
Llegamos a una primer conclusión importante. Las variables, guardan relación lineal con la variable objetivo (especialmente eFG y porcentaje de pérdidas) pero son independientes entre sí.

Modelicemos pues, el rating ofensivo en función de los cuatro factores propuestos:

```{r}
model_offesive_rating<- lm(Off_Rat~., data=data_ataque)
summary(model_offesive_rating)
```
La fórmula obtenida es por tanto:
$Rating\_Ofensivo=0.315316+1.465926eFG+0.645129Off\_Reb-1.398715Pct\_To+0.333343FTR$

Analizando la tabla de coeficientes, vemos que todas las variables aportan valor.

Por último, su $R^2$ ajustado es de 98%. Es decir, nos encontramos ante un ajuste realmente bueno.

Repitamos el análisis para el Rating Defensivo.

**Rating defensivo en función de los Four Factors de Dean Olliver**

```{r,eval=TRUE,echo=TRUE}
# Rating de defensa
data_defensa <- data_teamopp[c("Def_Rat","eFG_Opp","Off_Reb_Opp","Pct_To_opp","FTR_opp")]
corr_defensa <- round(cor(data_defensa),2)
corr_defensa
```
Como era de suponer, las conclusiones obtenidas en el análisis de correlación son análogas a las del apartado anterior en cuando a pesos e independencia lineal de la variables.

Modelizamos ahora el rating defensivo:
```{r}
model_defensive_rating<- lm(Def_Rat~., data=data_defensa)
summary(model_defensive_rating)
```
La fórmula obtenida es por tanto:
$Rating\_Defensivo=0.32545+1.46506eFG\_Opp+0.64297Off\_Reb\_Opp-1.33526Pct\_To\_Opp+0.24327FTR\_Opp$

Analizando la tabla de coeficientes, vemos que todas las variables aportan valor.

Por último, su $R^2$ ajustado es de 93.4%. Es decir, algo peor que para el caso del rating ofensivo pero de nuevo un ajuste muy bueno.

En conclusión, podemos estimar el rating ofensivo y defensivo de un equipo en base a solo cuatro variables construidas desde su boxscore. Así, podremos estimar qué rating ofensivo podríamos esperar si logramos subir dos puntos el porcentaje de rebote por ejemplo o reducir el porcentaje de pérdidas.


## Regresión logística para estimar victoria
Vamos a ser aún más ambiciosos. Hemos sido capaces de estimar cómo de bueno o malo será nuestro ataque pero, a la hora de ganar un partido, ¿Qué signfica eso?

El objetivo de este apartado es estimar la probabilidad de victoria en base a los ocho factores (los cuatro de ataque y los cuatro de defensa) a los que añadiremos la variable de si el equipo ha jugado en casa o no.

El primer paso por tanto es definir nuestro dataset:
```{r,eval=TRUE,echo=TRUE}
datos_logit<-data_teamopp[c("eFG","Off_Reb","Pct_To","FTR","eFG_Opp","Off_Reb_Opp",
                            "Pct_To_opp","FTR_opp","Win","Local")]

```

Vamos a dividir nuestro dataframe en dos subconjuntos, el 70% para realizar el modelo y el 30% para validarlo.

```{r}
set.seed(430)
default_idx = createDataPartition(datos_logit$Win, p = 0.7, list = FALSE)
training = datos_logit[default_idx, ]
testing = datos_logit[-default_idx, ]
```

Ahora estamos en condiciones de modelizar. Si anteriormente nos encontrábamos ante un problema de regresión, actualmente es un problema de clasificación cuyo clasificador es binario. 

Podríamos aplicar diferentes técnicas de modelización. En este caso, optaremos por una regresión logística:

```{r}
model_victoria <- glm(formula=Win ~ . , data=datos_logit, family=binomial(link="logit"))
summary(model_victoria)
```
De nuvo, analizando la tabla de coeficientes vemos que todas las variables son explicativas. Además, de que cada variable ofensiva con respecto a su homóloga defensiva, como es lógico, tiene peso similar y el signo cambiado.

Nos surge ahora la pregunta, ¿Cómo de bueno es nuestro modelo? Vamos a analizarlo:

```{r}
prediccion_test <- format(round(predict(model_victoria,testing,type="response")))
confusionMatrix(as.factor(prediccion_test),as.factor(testing$Win))
```
El accuracy es del 93.3%. Es decir, de las 150 observaciones de test, el modelo es capaz de acertar 140, lo que son unos resultados muy buenos. 

Otro estadístico importante cuando se analizan regresiones logísticas es el ROC, que nos da una idea de cómo de bien ordena un modelo. Es decir, cuantas veces nos equivocamos por cada acierto.

Calculemos su área bajo la curva .

```{r}
rocobj <- roc( datos_logit$Win, predict(model_victoria, datos_logit), 
               auc = TRUE, ci = TRUE )
print(rocobj)
```

En este caso, el ROC es de 99.4%, es decir, de nuevo tenemos un modelo casi perfecto.


## Clustering de jugadores

El último paso de este proyecto es ambicioso. Nos ponemos en la piel del director deportivo de uno de los equipos con un proyecto con recursos limitados.

Quiere hacer la mejor plantilla posible, con el mínimo gasto. Para ello, parte del mejor quinteto de la Euroliga y por cada jugador, quiere alternativas con nombres de jugadores que puedan tener un rendimiento similar pero menor precio (obviamente el mejor quinteto será por lo general el más caro).

Para ello, nos piden soporte. Planteamos para ello un proyecto que se dividirá en las siguientes fases:

* Depuración de datos.
* Definición de estadísticos para jugadores individuales.
* Búsqueda de jugadores de perfil similar.
* Presentación del informe.

**Depuración de datos.**

Comencemos depurando los datos. Para ello, eliminaremos del dataframe aquellos registros en los que el jugador en cuestión haya jugado menos minutos de los que consideramos relevantes, que lo delimitamos en un cuarto (salvo que el motivo sea por expulsión).

```{r,eval=TRUE,echo=TRUE}
data_players_relevant <- data_players[data_players$Min>10 | data_players$Cm.x==5,]
```

Hemos reducido la muestra `r nrow(data_players) - nrow(data_players_relevant)` registros.

Buscaremos ahora eliminar aquellos jugadorse que no hayan jugado un número mínimo de partidos, ya que queremos un análisis estable y no que esté influenciado por un mal o buen rendimiento de un solo partido.

Seleccionamos aquellos jugadores que al menos hayan jugado un 20% de los partidos. Es decir, 6 partidos.

```{r,eval=TRUE,echo=TRUE}
jugador_partido <- data.frame(table(data_players_relevant$PlayerName))
colnames(jugador_partido)[1]<-"PlayerName"
colnames(jugador_partido)[2]<-"Played_games"
jugador_partido <- jugador_partido[jugador_partido$Played_games>5,]

data_players_relevant<-merge(data_players_relevant, jugador_partido)
```

La definición de estadísticos se realizó en el apartado de enriquecimiento de datos, por lo que no es necesario volver a realizarlo. Ahora tenemos el dataframe con los candidatos:

```{r,eval=TRUE,echo=TRUE}
data_players_cluster <- data_players_relevant[,c("PlayerName", "Assist_pct", "Turnover_pct",
                                                 "Offensive_Reb_pct", "eFG_player",
                                                 "TS_player", "Usage_rate",
                                                 "Points_per_possesion",
                                                 "ThreePointers_ratio", "Defensive_Reb_pct",
                                                 "FTR_player", "Hollinger_Assist_ratio",
                                                 "Pomeroy_Assist_ratio", "Steal_pct",
                                                 "Block_pct")]
```

Aplicamos ahora el algoritmo k-Means que nos dará, los jugadores que más se parezcan en función de los estadísticos seleccionados en el paso anterior y la distancia entre los mismos. Cada factor tendrá el mismo peso.

Preparamos pues los datos agrupándolos por juador para todos los partidos:

```{r,eval=TRUE,echo=TRUE}
dt <- data.table(data_players_cluster)
acumulados_player<-dt[,list(Assist_pct=mean(Assist_pct),
Turnover_pct=mean(Turnover_pct),
Offensive_Reb_pct=mean(Offensive_Reb_pct),
eFG_player=mean(eFG_player),
TS_player=mean(TS_player),
Usage_rate=mean(Usage_rate),
Points_per_possesion=mean(Points_per_possesion),
ThreePointers_ratio=mean(ThreePointers_ratio),
Defensive_Reb_pct=mean(Defensive_Reb_pct),
FTR_player=mean(FTR_player),
Hollinger_Assist_ratio=mean(Hollinger_Assist_ratio),
Pomeroy_Assist_ratio=mean(Pomeroy_Assist_ratio),
Steal_pct=mean(Steal_pct),
Block_pct=mean(Block_pct)),by=PlayerName]
```

Aplicamos ahora el algoritmo k-means:
```{r,eval=TRUE,echo=TRUE}
set.seed(121)
km.res <- kmeans(acumulados_player[,-1], 15)
acumulados_player$cluster<-km.res$cluster
```

Definimos el quinteto ideal y vamos a dar alternativas por puesto:
```{r}
quinteto_ideal<-c("MICIC, VASILIJE","LARKIN, SHANE","DATOME, LUIGI",
                  "SHENGELIA, TORNIKE", "TAVARES, WALTER")
```

Calculamos los jugadores que comparten cluster con Micic. De ellos, escogeremos los que tengan los atributos en general más parecidos, o lo que es lo mismo, los que menos distancia entre su vector de atributos tengan.
```{r}
i <-1
aux<-acumulados_player[acumulados_player$PlayerName==quinteto_ideal[i],]$cluster
distancias<-dist(acumulados_player[acumulados_player$cluster==aux,][,-1],upper = TRUE)
nombres_cluster<-acumulados_player[acumulados_player$cluster==aux,]$PlayerName
df <- melt(as.matrix(distancias), varnames = c("row", "col"))
df2<-df[df$row ==which(nombres_cluster==quinteto_ideal[i]),]
df2$nombre<-nombres_cluster
df2<- df2[order(df2$value),]
print("Recomendaciones Base")
print(head(df2$nombre[df2$row!=df2$col],5))
```

Como comprobamos, las recomendaciones son basante acertadas. Cinco bases, con un perfil relativamente anotador:
- Sergio Rodríguez.
- Malcolm Delaney.
- Theo Maledon.
- Maodo Lo
- Sam Van Rossom.

Si tuviearmos un listado con posibles salarios, podríamos adaptar el problema a optimizar nuestro presupuesto.

Analicemos ahora las recomendacioens para el puesto de escolta:
```{r}
i <-2
aux<-acumulados_player[acumulados_player$PlayerName==quinteto_ideal[i],]$cluster
distancias<-dist(acumulados_player[acumulados_player$cluster==aux,][,-1],upper = TRUE)
nombres_cluster<-acumulados_player[acumulados_player$cluster==aux,]$PlayerName
df <- melt(as.matrix(distancias), varnames = c("row", "col"))
df2<-df[df$row ==which(nombres_cluster==quinteto_ideal[i]),]
df2$nombre<-nombres_cluster
df2<- df2[order(df2$value),]
print("Recomendaciones Escolta")
print(head(df2$nombre[df2$row!=df2$col],5))
```
En este caso nos recomienda de nuevo a jugadores del perfil anotador de Larkin. John Dibartolomeo, immer Fredette, James Nunally y Rokas Giedriatis.. Sin embargo, nos llama la atención la aparición de Nikola Mirotic en esta lista, un jugador de perfil interior. Analizando en más detalle, vemos qeu sus datos en cuanto a importancia del lanzamiento exterior o creación de juego (estadísticos relacionados con asistencias) son más propios de un jugador exterior.

Queremos encontrar ahora candidatos al puesto de alero:
```{r}
i <-3
aux<-acumulados_player[acumulados_player$PlayerName==quinteto_ideal[i],]$cluster
distancias<-dist(acumulados_player[acumulados_player$cluster==aux,][,-1],upper = TRUE)
nombres_cluster<-acumulados_player[acumulados_player$cluster==aux,]$PlayerName
df <- melt(as.matrix(distancias), varnames = c("row", "col"))
df2<-df[df$row ==which(nombres_cluster==quinteto_ideal[i]),]
df2$nombre<-nombres_cluster
df2<- df2[order(df2$value),]
print("Recomendaciones Alero")
print(head(df2$nombre[df2$row!=df2$col],5))
```
Como alternativas a Gigi Datome, nos presenta Ron Baker, Petteri Koponen, Jaycee Carroll, Aaron Doornekamp y Alex Abrines. Aleros con características de tirador. 

Si analizamos ahora las alternativas al puesto de ala pívot, el algoritmo nos da:
```{r}
i <-4
aux<-acumulados_player[acumulados_player$PlayerName==quinteto_ideal[i],]$cluster
distancias<-dist(acumulados_player[acumulados_player$cluster==aux,][,-1],upper = TRUE)
nombres_cluster<-acumulados_player[acumulados_player$cluster==aux,]$PlayerName
df <- melt(as.matrix(distancias), varnames = c("row", "col"))
df2<-df[df$row ==which(nombres_cluster==quinteto_ideal[i]),]
df2$nombre<-nombres_cluster
df2<- df2[order(df2$value),]
print("Recomendaciones Ala Pívot")
print(head(df2$nombre[df2$row!=df2$col],5))
```
como opción a Livio Jean-Charles, una de las sopresas de la temporada de Asvel, Cory Higgins, Adrien Moerman, Konstantinos Mitoglou o Vladimir Micov.

Por último para alternativas a uno de los mejores cincos de la competición pero con un caché muy elevado (Walter Tavares), obtenemos:
```{r}
i <-5
aux<-acumulados_player[acumulados_player$PlayerName==quinteto_ideal[i],]$cluster
distancias<-dist(acumulados_player[acumulados_player$cluster==aux,][,-1],upper = TRUE)
nombres_cluster<-acumulados_player[acumulados_player$cluster==aux,]$PlayerName
df <- melt(as.matrix(distancias), varnames = c("row", "col"))
df2<-df[df$row ==which(nombres_cluster==quinteto_ideal[i]),]
df2$nombre<-nombres_cluster
df2<- df2[order(df2$value),]
print("Recomendaciones Pívot")
print(head(df2$nombre[df2$row!=df2$col],5))
```
a Ahmet Duveriouglu, Kyle Hines del CSKA, Colton Iverson de Zénit y Jan Vesely.

En conclusión, hemos obtenido unas cuantas alternativas que podríamos encontrar en el mercado a estos jugadores.


****

\newpage
# Exportación de datos finales

A continuación vamos a exportar nuestros dataframes finales a un archivo csv. Estos archivos se llamarán euroleague_scoreboards_clean.csv, euroleague_stats_per_game_clean.csv y euroleague_stats_per_team_clean.cs Utilizamos la función write.csv2() para exportar el fichero en formato csv español:

```{r,eval=TRUE,echo=TRUE}
write.csv2(data_scoreboards, row.names = FALSE, 
           file = "../csv/euroleague_scoreboards_clean.csv")

write.csv2(data_euroleague, row.names = FALSE, 
           file = "../csv/euroleague_stats_per_game_clean.csv")

write.csv2(data_team, row.names = FALSE, 
           file = "../csv/euroleague_stats_per_team_clean.csv")

write.csv2(data_teamopp, row.names = FALSE, 
           file = "../csv/euroleague_team_and_opponent_clean.csv")
```

Estos nuevos datasets también estarán disponibles en el repositorio de GitHub mencionado en el primer apartado de este documento.

****

\newpage
# Representación de los resultados a partir de tablas y gráficas
## Comparativa de equipos (Ataque vs. Defensa)

Para la primera representación gráfica vamos a realizar una comparativa entre equipos utilizando los estadísticos que se crearon anteriormente para definir la eficiencia en defensa y en ataque. Para ello, utilizaremos un diagrama del estilo del [\textcolor{blue}{cuadrante Mágico de Gartner}](https://www.euroleague.net/), en el que dividiremos a los equipos en cuatro cuadrantes. 

El primer paso consistirá en crear una tabla en la que agrupemos a los equipos en base a la media de las variables `Off_Rat` y `Def_Rat` de todos los partidos:
```{r,eval=TRUE,echo=TRUE}
data_team_ratings <- as.data.frame(data.table(data_teamopp)[, .(mean(Off_Rat*100), 
                                                                mean(Def_Rat*100))
                                                            ,by = Team])
data_team_ratings
```

Ahora que ya disponemos de los datos necesarios, procedemos a crear nuestro gráfico mediante la función `ggplot()`:
```{r,eval=TRUE,echo=TRUE}
p <- ggplot(data_team_ratings, aes(V1, V2))

# Para facilitar la lectura de este informe, se han ocultado las distintas 
# opciones de configuración del gráfico. No obstante, se pueden consultar en
# el fichero practica2.Rmd con el código fuente desde el que se ha generado
# este pdf.
```

```{r,eval=TRUE,echo=FALSE}
p <- p + scale_x_continuous(expand = c(0, 0), limits = c(100, 130)) 
p <- p + scale_y_continuous(expand = c(0, 0), limits = c(105, 120))

p <- p + labs(x="Eficiencia Ataque",y="Eficiencia Defensa")
p <- p + theme(axis.title.x = element_text(hjust = 0, vjust=2, colour="black",size=10,face="bold"))
p <- p + theme(axis.title.y = element_text(hjust = 0, vjust=0, colour="black",size=10,face="bold"))

p <- p + theme(
  axis.ticks.x=element_blank(), 
  axis.text.x=element_blank(),
  axis.ticks.y=element_blank(),
  axis.text.y=element_blank()
)

p <- p+ggtitle("Comparativa de equipos en base a la eficiencia defensiva y de ataque")

p <- p +
  annotate("rect", xmin = 115, xmax = 130, ymin = 112.5, ymax = 120, fill= "#F8F9F9")  + 
  annotate("rect", xmin = 100, xmax = 115, ymin = 105, ymax = 112.5 , fill= "#F8F9F9") + 
  annotate("rect", xmin = 115, xmax = 130, ymin = 105, ymax = 112.5, fill= "white") + 
  annotate("rect", xmin = 100, xmax = 115, ymin = 112.5, ymax = 120, fill= "white")

p <- p + geom_point(colour = "#2896BA", size = 2) 
p <- p  + geom_text(aes(label=Team),colour="#2896BA", hjust=0, vjust=-1, size=3.2)

p <- p + theme(panel.border = element_rect(colour = "black", fill=NA, size=0.5))
p <- p + geom_hline(yintercept=112.5, color = "black", size=0.25)
p <- p + geom_vline(xintercept=115, color = "black", size=0.25)

p <- p + geom_label(aes(x = 103, y = 119, label = "Mal ataque"), color = "red")
p <- p + geom_label(aes(x = 103.25, y = 118, label = "Mala defensa"), color = "red")

p <- p + geom_label(aes(x = 127, y = 119, label = "Buen ataque"), color = "#1ba10a")
p <- p + geom_label(aes(x = 127, y = 118, label = "Mala defensa"), color = "red")

p <- p + geom_label(aes(x = 103, y = 107, label = "Mal ataque"), color = "red")
p <- p + geom_label(aes(x = 103.5, y = 106, label = "Buena defensa"), color = "#1ba10a")

p <- p + geom_label(aes(x = 127, y = 107, label = "Buen ataque"), color = "#1ba10a")
p <- p + geom_label(aes(x = 126.75, y = 106, label = "Buena defensa"), color = "#1ba10a")
```

```{r,eval=TRUE,echo=TRUE}
gt = ggplot_gtable(ggplot_build(p))
gt$layout$clip[gt$layout$name=="panel"] = "off"
grid.draw(gt)
```

En la página web de la euroliga tenemos disponible la clasificación de los equipos hasta la jornada 28, que es la última jornada que se ha disputado hasta la fecha (31 de mayo de 2020). Se puede acceder a esta clasificación haciendo [\textcolor{blue}{click aquí}](https://www.euroleague.net/main/standings?gamenumber=28&phasetypecode=RS&seasoncode=E2019). 

A modo de resumen, los primeros puestos son los siguientes:

**Posición** |**Equipo**              |**Victorias**|**Derrotas**|**Pts+**|**Pts-**| 
:-----------:|------------------------|:-----------:|:----------:|:------:|:------:|
1.           | Anadolu Efes Istanbul  | 24          | 4          | 2432   | 2166   |
2.           | Real Madrid            | 22          | 6          | 2371   | 2165   |
3.           | FC Barcelona           | 22          | 6          | 2357   | 2193   |

Y los últimos puestos:

**Posición** |**Equipo**              |**Victorias**|**Derrotas**|**Pts+**|**Pts-**| 
:-----------:|------------------------|:-----------:|:----------:|:------:|:------:|
16.           | ALBA Berlin           | 9           | 19         | 2304   | 2423   |
17.           | FC Bayern Munich      | 8           | 20         | 2064   | 2281   |
18.           | Zenit St Petersburg   | 8           | 20         | 2055   | 2240   |

Si comparamos la posición real en la clasificación con la posición de cada equipo en el gráfico vemos que queda completamente claro la relación entre las variables analizadas. Los equipos que están en los primeros puestos se caracterizan por un buen ataque y una buena defensa y los equipos que van últimos tienen mala defense y mal ataque.

\newpage
## Correlaciones
Estos gráficos son complementarios a los presentados en la sección 5.2, de manera más visual.
En probabilidad y estadística, la correlación indica la fuerza y la dirección de una relación lineal y proporcionalidad entre dos variables estadísticas. Se considera que dos variables cuantitativas están correlacionadas cuando los valores de una de ellas varían sistemáticamente con respecto a los valores homónimos de la otra: si tenemos dos variables (A y B) existe correlación entre ellas si al disminuir los valores de A lo hacen también los de B y viceversa. La correlación entre dos variables no implica, por sí misma, ninguna relación de causalidad.

```{r,eval=TRUE,echo=TRUE}
ggcorrplot(corr_ataque, type = "upper", lab = TRUE)
ggcorrplot(corr_defensa, type = "upper", lab = TRUE)
```

\newpage
## Curva ROC
La curva ROC es la representación de la razón o ratio de verdaderos positivos (VPR = Razón de Verdaderos Positivos) frente a la razón o ratio de falsos positivos (FPR = Razón de Falsos Positivos) también según se varía el umbral de discriminación (valor a partir del cual decidimos que un caso es un positivo). La idea de la curva ROC es que tenga la mayor área bajo la curva posible y, en general, nos interesa que la pendiente al principio sea muy elevada para disparar el área de captura de verdaderos positivos en relación a los errores cuanto antes.

```{r,eval=TRUE,echo=TRUE}
plot.roc( rocobj, legacy.axes = TRUE, print.thres = "best", 
          print.auc = TRUE, auc.polygon = FALSE, max.auc.polygon = FALSE, 
          auc.polygon.col="gainsboro", col = 2, grid = TRUE )
```
****

\newpage
# Conclusión

Como conclusión al trabajo, queríamos destacar:
- El Data Science tiene infinidad de campos a los que contribuir con su crecimiento y el deporte profesional es uno de ellos, donde además, su uso por lo general apenas está explotado.
- La creación de nuevos estadísticos que depuren los datos y mejoren la percepción de los mismos, es uno de los puntos donde se está poniendo el foco. 
- Uno de los mayores problemas a la hora de analizar datos del mundo profesional es la mala calidad de las bases de datos. Somos consciente de que nuestra aproximación es una demostración de que la Ciencia de Datos puede servir como apoyo al baloncesto pero que no es realista desde el putno de vista de interpretación. Para ser más precisos es necesario bases de datos de calidad mayor, en los que se analice con más detalle los jugadores (veces que botan por derecha o izquierda), los quintetos con los que juegan (no es lo mismo jugar con un buen base a la hora de obtener tiros que con un base flojo), los rivales o el mometno en el que se toman las estad´siticas (es obvio qeu meter una canasta en los minutos finales o clutch es mucho más valorado que los jugadores cuyo mejor performance es al principio o en partidos resueltos).
- Las aplicaciones de la Ciencia de datos al baloncesto son infinitas y de distintas aplicaciones, desde el entrenador que realiza el scouting y plantea el partido, el que analiza el resultado y los fallos que se han tenido o incluso la hora de que el director técnico confeccione el equipo.
- Entendemos la ciencia sobre los datos como un complemento necesario a la hora de tomar decisiones en el día a día de deporte, pero no como un sustitutivo de las personas. Al final, siempre que se trabaja con personas hay muchos datos que son imposibles de medir y que podrían contribuir a la hora, por ejemplo, de crear tu plantilla en pretemporada.


****
# Contribuciones al trabajo

**Contribuciones**              |  **Firma**                    | 
--------------------------------|:-----------------------------:|
Selección del dataset           | MSP, AAG
Creación del repositorio GitHub | MSP, AAG
Desarrollo código en R          | MSP, AAG
Redacción de las respuestas     | MSP, AAG